---
title: "Define the problem"
author: 
  - name: "Nguyễn Đức Phú"
    email: ducphu.1906@gmail.com
    affiliations:
      - name: Ho Chi Minh University of Technology
        city:  Tp. Hồ Chí Minh
        state: Vietnam
execute: 
  cache: true
  echo: false
format: 
  html:
    toc: true 
    toc-title: Contents
    toc-location: left
    
    embed-resources: true
    number-sections: true 
    number-depth: 3
    html-math-method: katex

    code-fold: true
bibliography: references.bib
---

# Input

What we have:

- 53 datasets of 53 times series data (may be duplicated)
- one LABEL dataset (raw)

```{r}
list.files("dataset/1501")
```

# Output

Following the design of experiment (DOE), we define the outcome and our objectives

## Outcome

Since the LABEL dataset is the result of checking semi-products' quality criterias such as:

```{r}
df <- openxlsx::read.xlsx("dataset/labels.xlsx", sheet = "Sheet2", detectDates = TRUE)
colnames(df)
```

Quality criterias such as `AD`, `Vis`, `pH`, `SG` with quite enough data can be used as dependent variables for the thesis

## Objectives

We have already identified the target. The next task is to state the objectives.

Some options are

- Predict the value of quality critierias, or the `regression` problem
- Predict whether the batch is qualified, or the `binary classification` problem
- Predict which level of `goodness` the batch belongs to, or the `multi-label classification` problem

**Notes**:

1. Search scientific publication for these above terms: `regression`, `binary classification` and `multi-label classification`.
2. Some survey about the amount, advantages, dis-advantages of each type of problem in manufacturing industries.
3. Define levels of 'goodness' in industries and which papers used the same term.

The objectives of thesis is then:

1. With statistical analysis, we will perform feature engineering on raw data of the manufacturing processes to select most impactful factors on the quality criterias of the batch.

2. Artificiall intelligence models are then constructed with the aim to reach 95\% of confidence intervals when predicting the target.


# Approaches

## Improving performances with statistic-based feature selection

We have total of 53 dataset, over 40 of them are data from machine, which results in many features can be extracted.

To enhance the performance of models, we conduct statistic analysis to determine the impact of features on the outcome defined above

For example, how the average of temperature in the batch has correlation with the pH value.

Regarding the statistic analysis we mentioned, some approaches can be:

- ***Hypothesis testing*** to accept or reject the effect of factors on the outcome
- **Analysis of correlation**  to select features 

According to [@CHANDRASHEKAR201416], there are 3 types of methods `Filter`, `Wrapper`, and `Embedded`.

- **Filter** use variable ranking techniques for variable selection by ordering.
- **Wrapper** use predictor as black box and the performances as the objective function to evaluate the variable subset.
- **Embedded** incorporate the feature selection as part of the training process.

### Using Filter

`Hypothesis testing` and `analysis of correlation` use $p\_value$ and $corr$, respectively, as the criteria for ranking. Therefore, both of them belongs to **filter** class.

`Mutual information` (MI) and other methods estimating the MI are also candiates as a principle criteria, such as the measure $K$ of the Kullback-Leibler divergence or Conditional Mutual Information

One of the drawbacks of ranking methods is that they do not eliminate redundant variables in [@guyon2003introduction]. Also, features may be less effective when standing alone but have impact on the target when in form of combination with others in [@guyon2003introduction; @xu2010discriminative].

### Using Wrapper

In [@CHANDRASHEKAR201416], Wrapper can be splitted to two main categories, namely `Sequential Selection Algorithms` and `Heuristic Search Algorithms`.

The main drawbacks for Wrapper methods is that they require computations to select optimal set of features. By using classifiers and their performances as scoring criteria, Wrapper is also vulnerable with model overfitting in [@KOHAVI1997273].

### Using Embedded

Embedded methods want to reduce the computations used by Wrapper by incorporating the feature selection in the training process. Also by combining the ranking criteria as MI and the classificatin models, Embedded methods can limit somes of the cons of Filter approaches.

In [@battiti1994using; @Kwak2002; @peng2005feature], MI is used with other classifiers to acquire the feature subset. Using weights of a classification model as a ranking table to remove feature is also widely used, in [@guyon2003introduction; @guyon2002gene].

### Others

Ensemble feature selection in [@haury2011influence; @abeel2010robust] is a novel candiate that they conduct single feature selection on a bootstrap data sample and aggregate to a final feature set.

## Explainable AI

## Web-based application

After all the analysis and modeling, a Shiny Application as demo with [@shiny].