# Data exploration

We have already discussed the methodology in [@sec-method]. This section will discuss how we transform the raw data, mostly in format of time series, into useable and meaningful features. These features will be the main character in the following [@sec-modeling]. Some of algorithms resulted from this section also come handy in the deployment phase, joining in the phase to pre-process the new inputs for model inference.

The layout of this section is listed as below:

- ***Label preprocessing***. Labels are validated and added the information about batches. The datasets at the end of this section are the target for training models.
- ***Feature processing***. Next, this section describe how we cut the data from machines and devices to smaller parts, identified by the batch name.
- ***Feature engineering***. Finally, algorithms are introduced in this section to transform the *batches binded* time series to features.

## Label preprocessing {#sec-label-processing}

The label which means the results of quality checking process for each batches are manually recorded in format of a spreadsheet. This section conducts analysis, validation and cleaning processes to transform the spreadsheet to a label dataset for training.
```{r}
library("data.table")
```

```{r}
df <- openxlsx::read.xlsx("dataset/labels.xlsx", sheet = "Sheet2", detectDates = FALSE)
```

```{r}
dt <- data.table::data.table(df)
dt <- dt[, .(TUẦN, Ngày.tháng.năm, Ca, Mixer, Code.dầu, KL.theo.mixer, KL.thực.tế, Nước.rework, Batch, Màu, Mùi, AD, Vis, pH, SG)]
```

The original dataset consists a total of `r ncol(df)` columns. Some of them contains non-relevant or non-informative metadata data which will be removed. Since the datasets of machine signals all belongs to only mixer 1501, only the label for batches in mixer 1501 should be kept. The values of mixers that can be founded in the spreadsheet are `r unique(dt$Mixer)`. As we discussed, only Mixer 1501 are kept.

```{r}
dt1501 <- dt[Mixer == 1501, ]
```

Within the resulting dataset, numerical label fields such as *AD*, *pH*, *Vis*, and *SG* are kept and will continue to be processed.

### AD {.unnumbered .unlisted}

```{r, warning = FALSE}
dt1501_ad <- dt1501$AD
dt_numeric_ad <- as.numeric(dt1501_ad)
```

The spreadsheet is manually filled in and the format may not be infered correctly. Hence, converting to the correct format, namely numeric, for these label fields is the first task. In the process, we happen to face `r length(dt_numeric_ad[is.na(dt_numeric_ad)])` cases that we failed to convert. Investigating these case, we found that most of the value are missing, accounting for `{r} length(dt1501_ad[is.na(dt_numeric_ad)]) / length(dt_numeric_ad[is.na(dt_numeric_ad)]) * 100` $%$ of the cases. The other two are spelling errors.

```{r, warning = FALSE}
dt1501_ad <- dt1501[, .(TUẦN, Ngày.tháng.năm, Ca, Mixer, Code.dầu, KL.theo.mixer, KL.thực.tế, Nước.rework, Batch, AD)]
dt1501_ad[, AD := as.numeric(AD)]
dt1501_ad <- dt1501_ad[!is.na(AD), ]
```

The number of records in the dataset for the criteria *AD* is `{r} nrow(dt1501_ad)`.

```{r, warning = FALSE}
dt1501_ad <- dt1501_ad[, KL.theo.mixer := NULL]
dt1501_ad[, Nước.rework := as.numeric(Nước.rework)]
```

The format of value in column **Batch** is important since it is the key to link the labels and the time series which will be used as inputs. Therefore, a validation step is required to ensure the manually recorded name of batches is good to use.

As a internal policy, the Batch name is a string of characters whose format is constant

> YYWWDS'M'MBB

, in which:

-   YY is the year
-   WW is the week number
-   D is the day of the week, with Monday has value of $1$
-   S is the shift in day
-   'M' is the letter M, stands for *mixer*.
-   M is the identifing code for the mixer
-   BB is the order of batch in corresponding shift.

The number of *batch names* that are in correct format is `{r} sum(stringi::stri_detect_regex(dt1501_ad$Batch, pattern = "[0-9]{6}[Mm][0-9]{3}"))`. It means all the value for this column are ready to use. For consistency, we convert all the lowercase *m* to uppercase.

```{r}
dt1501_ad[, Batch := stringi::stri_trans_toupper(Batch)]
dt1501_ad <- dt1501_ad[, .(Code.dầu, Nước.rework, Batch, AD)]
colnames(dt1501_ad) <- c("sku", "amount_rework", "batch", "label")
```

```{r}
data.table::setcolorder(dt1501_ad, c("label", "batch", "sku", "amount_rework"))
qs::qsave(x = dt1501_ad, file = "data/dt_label_ad.qs")
```

### Viscosity {.unnumbered .unlisted}
```{r, warning = FALSE}
dt1501_vis <- dt1501[, .(Vis, Batch, Code.dầu, Nước.rework)]
dt1501_vis[, Vis := as.numeric(Vis)]
dt1501_vis <- dt1501_vis[!is.na(Vis), ]
dt1501_vis[, Nước.rework := as.numeric(Nước.rework)]
colnames(dt1501_vis) <- c("label", "batch", "sku", "amount_rework")
```
We follow the same approach above for the quality criteria **Viscosity**, or *Vis*, which are to convert the type of data, remove missing values and spelling erorrs. However, in the case of *viscosity*, thanks to the domain knowledge provided by experts in the industry, we know that the range of the viscosity of different products can vary a lot. Therefore, a more careful approach for the label of viscosity is conducted.

First, we summary the current situation of column *Vis*, as showed below

```{r}
#| label: tbl-summary-vis
#| tbl-cap: Descriptive analysis for column *Vis* 
tbl_summary <- summary(dt1501_vis$label)
knitr::kable(data.frame(Statistics = names(tbl_summary), Value = as.numeric(tbl_summary)))
```

As in the [@tbl-summary-vis], we can see that the min value for Vis is $3.18$ and the max is $18253$, which are not possible values of viscosity that the products can achieve. Hence, they may be outliers. To detect the outlier, we visualize the distribution of viscosity value in the following figure.

```{r}
#| label: fig-box-vis
#| fig-cap: Distribution of products viscosity
#| fig-pos: "h"
fig_vis <- ggplot2::ggplot(data = dt1501_vis[label < 4000, ], mapping = ggplot2::aes(x = "label", y = label)) +
  ggplot2::geom_violin(fill = "gray") + ggplot2::theme_bw() 
plot(fig_vis)
```

Note that, in [@fig-box-vis], we eliminated the values above $4000$, which are cleary impossible based on the descriptive analytics in [@tbl-summary-vis]. The figure depicts that there are two distributions hidden in the distribution of viscosity values. This is because the dataset contains many of products that belongs to different stock-keeping units (SKUs), around `r length(unique(dt1501_vis$sku))` SKUs found in the dataset. Just like with *AD*, we also calculate the propotion of *batch name* following the correct format, which is `r sum(stringi::stri_detect_regex(dt1501_vis$batch, patter = "[0-9]{6}[Mm][0-9]{3}")) / nrow(dt1501_vis) * 100` $\%$.

```{r}
dt1501_vis[, Batch := stringi::stri_trans_toupper(batch)]
qs::qsave(dt1501_vis, "data/dt_label_vis.qs")
```

### pH {.unnumbered .unlisted}


### SG {.unnumbered .unlisted}

## Feature Processing {#sec-feature-processing}

Every times series contains millions of data points. Howevery, this times series are not so helpful when they stay in their raw format. It is because of the fact that labels are identified by batches, while the signal describing the context are not. Therefore, the very first time is to split the data into smaller sets correspondingly in the same time window as the labels.

The process can be simplified as:

1.  Find the time windows where the batch and the label belong to, namely the begin timestamp and end timestamp
2.  Filter the inputs in above time windows
3.  Preprocess the framed inputs into valueable features, namely the feature engineering process,

Notes that the word *valueable* is not quantifiable. More details about the methodology to refine the feature are discussed in [@sec-feature-engineering].

In this section, we describe detaily about the above process and the results from it. Each of following subsections is dedicated for a time series in the dataset.

### Build batches time windows

In the dataset, each data point in the time series **batch_name** is the name of the batch which was running at that time. Therefore, thanks to this time series, we can identify the beginning and ending of a batch, after cleaning and validating the data.

```{r}
library("magrittr")
library("data.table")
```

```{r, cache = TRUE}
df_batch_name <- data.table::fread("./dataset/1501/batch_name.csv")
```

Just like other time series, the **batch_name** has 3 columns `{r} names(df_batch_name)`, standing for timestamp, tag name, and value, respectively.

| Column | Data type                           |
|--------|-------------------------------------|
| TS     | `{r} class(df_batch_name[, TS])`    |
| Tag    | `{r} class(df_batch_name[, Tag])`   |
| Value  | `{r} class(df_batch_name[, Value])` |

: Data type of time series *batch_name*


```{r, cache = TRUE}
is_correct_format <- stringi::stri_detect_regex(as.character(df_batch_name$Value), pattern = "^[0-9]{9}$")
df_incorrect_format <- df_batch_name[!is_correct_format, ]
```

Using package *stringi* in [@gagolewski_stringi_2022] to detect the wrong format value, discussed in [@sec-label-processing], we find `{r} nrow(df_incorrect_format)` rows which has incorrect format. For example, the values that do not follow the pattern are `{r} unique(df_batch_name[!is_correct_format, Value])`. We remove them from the time series.

```{r, cache = TRUE}
df_correct_format <- df_batch_name[is_correct_format, ]
```

#### Filter the start and end of batches

After preprocessing the time series, we can get the beginning and the end of batch by filtering the data points belong to the batch and get the min, max value. However, this approach may lead to the situation when there are some noise in the time series.

To be more specific, if there is a error data point, whose timestamp is larger than the batch its value represents. Then the time window of the batch itself will be incorrect since the max value of timestampe will return the error data point.

Therefore, to maintain the order of the time series, we identify the starting point and the end of the batch by

1.  Browse through the time series
2.  Check if the value of current timestamp is the same as the previous one and the one after it.

-   If *True*, remove the data point.
-   Otherwise, keep the data point and go to the next one.

```{r, cache = TRUE}
is_same_lag <- as.logical(data.table::nafill(as.numeric(df_correct_format$Value == data.table::shift(df_correct_format$Value), type = "lag"), fill = 0))
is_same_lead <- as.logical(data.table::nafill(as.numeric(df_correct_format$Value == data.table::shift(df_correct_format$Value, type = "lead")), fill = 0))
df_trimmed <- df_correct_format[!(is_same_lag & is_same_lead), .(TS, Value)]
```

The number of rows after applying the above algorithm is `{r} nrow(df_trimmed)`, which is a odd number. Therefore, a validation is required to ensure the *Timestamp* and the *Batch Name* is compatible.

#### Validate the start and end of batches

In the above section, we determined the number of rows in the resulting data frame should have been a even number, since the batches are distingushed by a pair of the starting and endpoint. Therefore, in this section, we conduct an algorithm to identify the abnormal batches.

Batches are labeled abnormal when the **batch name** appears more than two times in the resulting table, following the reason stated above.

```{r}
counting_appearances <- df_trimmed[, .(count = .N), by = Value]
```

After aggregating the appearances, the number of **batch name** that appears different from two times is `{r} nrow(counting_appearances[count > 2, ])`. Some of them can be listed as `{r} head(counting_appearances[count > 2, ])$Value`.

We then investigate those outlier.

```{r}
v_is_abnormal_batches <- counting_appearances[count != 2, ]$Value
# df_trimmed[Value %in% v_is_abnormal_batches, ]
df_abnormal_batches <- df_trimmed[Value %in% v_is_abnormal_batches, ]
df_remove_candidates <- df_abnormal_batches[Value != data.table::shift(df_abnormal_batches$Value, type = "lag") & Value != data.table::shift(df_abnormal_batches$Value, type = "lead"), ]

df_removed <- df_trimmed[! (TS %in% df_remove_candidates$TS & Value %in% df_remove_candidates$Value), ]
df_last_candidates <- df_removed[Value != data.table::shift(df_removed$Value, type = "lag") & Value != data.table::shift(df_removed$Value, type = "lead"), ]

df_validated <- df_removed[! (TS %in% df_last_candidates$TS & Value %in% df_last_candidates), ]
```

The elimination follow these steps:

-   Determine which batches appear other than two times.
-   Remove data point whose `Value` is not the same as both the previous and the next neighbors.

The validated table has `{r} nrow(df_validated)` rows, all the data points satisfy the condition that either the `Value` of the row is the same as the previous one or the next one (the number of rows not satisfy is `{r} nrow(df_validated[Value != data.table::shift(df_validated$value, type = "lag") & Value != data.table::shift(df_validated$Value, type = "lead"), ])`).

Another needed validation is if the `TS` of the starting point is smaller than the `TS` of the ending point, finding `{r} nrow(df_validated[TS > data.table::shift(df_validated$TS) & mod(.I, 2), ])` rows that do not satisfy the condition.

We expected that each *batch name* will appear exactly two times. How

```{r}
df_batches <- data.table::data.table(
  batch_name = df_validated[seq(1, nrow(df_validated), 2), ]$Value,
  start = df_validated[seq(1, nrow(df_validated), 2), ]$TS,
  end = df_validated[seq(2,nrow(df_validated), 2), ]$TS
)
df_batches[, duration := as.numeric(end - start) / 60]
```

From the dataset above, we construct a so-called **batches** dataframe to store the starting and ending points of batches, indexed by the *batch name*. The duration of the batch can be calculated by the difference between two timestamps. This following table demonstrate the summary of batches duration.

```{r}
#| label: tbl-summary-duration
#| tbl-cap: Descriptive analysis of batches duration 
tbl_duration_sum <- summary(df_batches$duration)
knitr::kable(data.frame(Statistic = names(tbl_duration_sum), Value = as.numeric(tbl_duration_sum)))
```

According to the standardized process, the minimum and maximum time for a batch are 15 and 60 minutes, respectively. There are cases that batches can be lengthened to more than 3 hours. The number of batches whose duration are outside of the domain-defined range is `{r} nrow(df_batches[duration < 15 | duration > 180, ])`. The potential reasons for the outlier are

-   There is an incident that the process has to be paused for a long time.
-   There is machine errors, manufacturing machine and streaming infracstructure, that leads to incorrect data recording.

```{r}
df_batches <-df_batches[duration >= 15 & duration <= 180, ]
```

In this study, we ignore and remove these batches, `{r} nrow(df_batches)` data points remaining.

```{r, output = FALSE, eval = knitr::is_html_output()}
#| fig-cap: "Distribution of batches duration"
#| fig-pos: "h"
#| label: fig-batches-duration
fig_batches_duration <- ggplot2::ggplot(data = df_batches, mapping = ggplot2::aes(x = "", y = duration)) + 
  ggplot2::geom_boxplot(varwidth = TRUE, fill = "gray", outlier.colour = "red", outlier.size = .75, outlier.shape = 1) + 
  ggplot2::labs(title = "Plot of batches duration", x = "Duration", y = "Minutes")
  ggplot2::theme_bw()
ggplot2::ggsave("images/fid_batch_duration.svg", plot = fig_batches_duration)
```

![Distribution of batches duration](images/fid_batch_duration.svg){#fig-batches-duration fig-pos="h"}

The [@fig-batches-duration] demonstrates the distribution of batches duration. We can see that most of the batches last about 30 to 60 minutes. However, the number of batches that are marked outlier is remarkable. This can be interpreted as the manufacturing process is not stable and has high variance.

This section comes to an end after we receive a data table containing the time window of batches. With `{r} nrow(df_batches)` batches, the next phase is to engineer features by following steps stated in [@sec-feature-processing].

```{r, output = FALSE}
qs::qsave(x = df_batches, file = "data/df_batches.qs")
```

### Weight of main mixer

Continue the data processing phase, the next target is the time series of the weight of the main mixer. This section will use the result from the above one, filter and validate the data of product volume within batches.

```{r, cache = TRUE}
df_weight_main <- data.table::fread("dataset/1501/main_mixer_weight_of_main_mixer.csv")
df_weight_main <- df_weight_main[, .(TS, Value)]
data.table::setnames(df_weight_main, old = "Value", new = "weight_main")
```

```{r, cache = TRUE, eval = FALSE}
l_weight_main <- lapply(seq_len(nrow(df_batches)), function(index) {
   df <- df_weight_main[TS >= df_batches[index, start] & TS <= df_batches[index, end], ]
   df[, batch := df_batches[index, batch_name]]
   return(df)
 })
 qs::qsave(l_weight_main, "data/df_weight_main_mixer_batch_binded.qs")
```

```{r, cache = TRUE}
l_weight_main <- qs::qread("data/df_weight_main_mixer_batch_binded.qs")
```

```{r, output = FALSE, eval = knitr::is_html_output()}
fig_weight_main_1 <- ggplot2::ggplot(data = l_weight_main[[1]], mapping = ggplot2::aes(x = TS, y = weight_main)) +
  ggplot2::geom_line() +
  ggplot2::labs(title = paste("Weight of main mixer batch", unique(l_weight_main[[1]]$batch)), x = "Timestamp", y = "Weight of main mixer") +
  ggplot2::theme_bw()

fig_weight_main_2 <- ggplot2::ggplot(data = l_weight_main[[2]], mapping = ggplot2::aes(x = TS, y = weight_main)) +
  ggplot2::geom_line() +
  ggplot2::labs(title = paste("Weight of main mixer batch", unique(l_weight_main[[2]]$batch)), x = "Timestamp", y = "Weight of main mixer") +
  ggplot2::theme_bw()

ggplot2::ggsave("images/fig_weight_main_1.svg", plot = fig_weight_main_1)
ggplot2::ggsave("images/fig_weight_main_2.svg", plot = fig_weight_main_2)
```

::: {#fig-weight-main layout-ncol="2" fig-pos="h"}
![Weight of main mixer in batch 230111501](images/fig_weight_main_1.svg)

![Weight of main mixer in batch 230111502](images/fig_weight_main_2.svg)

An example of filtered of main mixer volume
:::

The time series of the volume of product follows the three phases:

1. Increasing at the beginning since the materials are dosed into main mixer.
2. Maintaining a level when flushing materials is done and the main task is to mix.
3. Decreasing at the end when the batches are done and the semi products are transfered to storage tank.

### Temperature of main mixer

The temperature of the product within the tank is also an important time series. It is because when the materials are dosed and mixed, the chemical reaction happened. Therefore, the temperature is often increasing at the start of the batches and move into a stable phase later.

```{r}
df_temp_main <- data.table::fread("dataset/1501/main_mixer_temperature_of_main_mixer.csv")
df_temp_main <- df_temp_main[!stringi::stri_detect_fixed(Tag, pattern = "input chlor water"), .(TS, Value)]
data.table::setnames(df_temp_main, old = "Value", new = "temp_main")
```

```{r, eval = FALSE}
l_temp_main <- lapply(seq_len(nrow(df_batches)), function(index) {
   df <- df_temp_main[TS >= df_batches[index, start] & TS <= df_batches[index, end], ]
   df[, batch := df_batches[index, batch_name]]
   return(df)
 })
qs::qsave(l_temp_main, "data/df_temp_main_mixer_batch_binded.qs")
```

```{r}
l_temp_main <- qs::qread(file = "data/df_temp_main_mixer_batch_binded.qs")
```
```{r}
#| fig-cap: An example of filtered of main mixer temperature
#| fig-subcap:
#| - Batch 230112504
#| - Batch 230113503
#| layout-ncol: 2
#| label: fig-temp-main
#| fig-pos: "h"
fig_temp_main_1 <- ggplot2::ggplot(data = l_temp_main[[10]], mapping = ggplot2::aes(x = TS, y = temp_main)) +
  ggplot2::geom_line() +
  ggplot2::labs(title = paste("Temperature of main mixer batch", unique(l_temp_main[[10]]$batch)), x = "Timestamp", y = "Temp of main mixer") +
  ggplot2::theme_bw()

fig_temp_main_2 <- ggplot2::ggplot(data = l_temp_main[[20]], mapping = ggplot2::aes(x = TS, y = temp_main)) +
  ggplot2::geom_line() +
  ggplot2::labs(title = paste("Temperature of main mixer batch", unique(l_temp_main[[20]]$batch)), x = "Timestamp", y = "Temp of main mixer") +
  ggplot2::theme_bw()
plot(fig_temp_main_1)
plot(fig_temp_main_2)
```

The [@fig-temp-main] depicts the above logic. However, the time period where the main mixer temperature is stable may be different for each batch. More detail about how we transform the filtered signal to features are discussed in [@sec-feature-engineering].

### Pressure of main mixer circulation system

The processing line contains multiple stations. The products are kept in the pump and moved around stations through a circulation system. The circulation also takes part in the cooling process for the semi product. Another role of the circulation system is to make sure the materials are mixed evenly.

According to experts, the pressure of pipes in a main mixer circulation system may hide the insights about the viscosity of the producted being mixed. The more dense the mixture is, the higher the pressure is.

```{r}
df_press_main <- data.table::fread("dataset/1501/main_mixer_pressure_of_circulation_pump.csv")
df_press_main <- df_press_main[, .(TS, Value)]
data.table::setnames(df_press_main, old = "Value", new = "press_main")
```

```{r, eval = FALSE}
l_press_main <- lapply(seq_len(nrow(df_batches)), function(index) {
   df <- df_press_main[TS >= df_batches[index, start] & TS <= df_batches[index, end], ]
   df[, batch := df_batches[index, batch_name]]
   return(df)
 })
qs::qsave(l_press_main, "data/df_press_main_mixer_batch_binded.qs")
```

```{r, cache = TRUE}
l_press_main <- qs::qread("data/df_press_main_mixer_batch_binded.qs")
```

```{r}
#| fig-cap: An example of filtered of main mixer pipe pressure of circulation system
#| fig-subcap:
#| - Batch 230111501
#| - Batch 230111502
#| layout-ncol: 2
#| label: fig-press-main
#| fig-pos: "h"
fig_press_main_1 <- ggplot2::ggplot(data = l_press_main[[1]], mapping = ggplot2::aes(x = TS, y = press_main)) +
  ggplot2::geom_line() +
  ggplot2::labs(title = paste("Pressure of circulation pipe batch", unique(l_press_main[[1]]$batch)), x = "Timestamp", y = "Circulation system press") +
  ggplot2::theme_bw()

fig_press_main_2 <- ggplot2::ggplot(data = l_press_main[[2]], mapping = ggplot2::aes(x = TS, y = press_main)) +
  ggplot2::geom_line() +
  ggplot2::labs(title = paste("Pressure of circulation pipe batch", unique(l_press_main[[2]]$batch)), x = "Timestamp", y = "Circulation system press") +
  ggplot2::theme_bw()
plot(fig_press_main_1)
plot(fig_press_main_2)
```

The values pictured in [@fig-press-main] has phases the can be easily detected. The pressure of the circulation system depends on steps in the manufacuring formulation. For example, when the formulation requires stronger mix, the values go high. Meanwhile the values are $0$ when the circulation pump is off. There may be correlation between the *pressure of the circulation system* and the *speed of circulation pump*, which we will explore more in [@sec-feature-engineering].

### Speed of main mixer circulation pump

In the above section, we filtered the time series of the pipe pressure in the circulation system of the main mixer. This section will discuss another factor in the mixing process, which is the speed of the pump used in the main mixer circulation system.

```{r, cache = TRUE}
df_speed_main <- data.table::fread("dataset/1501/main_mixer_speed_of_circulation.csv")
df_speed_main_pump <- data.table::fread("dataset/1501/main_mixer_speed_of_circulation_pump.csv")
df_speed_main <- df_speed_main[!stringi::stri_detect_fixed(Tag, pattern = "pump"), .(TS, Value)]
df_speed_main_pump <- df_speed_main_pump[, .(TS, Value)]
data.table::setnames(df_speed_main, old = "Value", new = "speed_main")
data.table::setnames(df_speed_main_pump, old = "Value", new = "speed_pump")
```

There are two time series in the set of machine signals that have the very same name for the *speed of circulation pump*, namely *speed_of_circulation* and *speed_of_circulation_pump*. We analyze these two signals to determine if they represent for the same information.

```{r}
#| fig-cap: Comparision two time series of circulation pump speed
#| fig-subcap:
#| - speed_of_circulation
#| - speed_of_circulation_pump
#| layout-nrow: 2
#| label: fig-compare-speed-main
df_sample_speed_main <- df_speed_main[TS >= df_batches[5000, start] & TS <= df_batches[5000, end], ]
df_sample_speed_pump <- df_speed_main_pump[TS >= df_batches[5000, start] & TS <= df_batches[5000, end], ]
fig_speed_main <- ggplot2::ggplot(data = df_sample_speed_main, mapping = ggplot2::aes(x = TS, y = speed_main)) +
  ggplot2::geom_line() + ggplot2::theme_bw()
fig_speed_pump <- ggplot2::ggplot(data = df_sample_speed_pump, mapping = ggplot2::aes(x = TS, y = speed_pump)) +
  ggplot2::geom_line() + ggplot2::theme_bw()
plot(fig_speed_main)
plot(fig_speed_pump)
```

Despite the fact that two time series are different, the *speed_of_circulation* is a newly installed signal and only available from `r min(df_speed_main$TS)`. Therefore, using it as a feature later is not possible. Hence, we discard the time series *speed_of_circulation*.

As we discussed in [@sec-base-vis], these four machine signals we conduct processing above are the key features for the baseline model of predicting viscosity. However, these time series are only pre-processed and still not in format of a features that can be used as model inputs. The [@sec-feature-engineering] will discuss more about how we turn these *batches binded* raw information into valuable features.

## Feature Engineering {#sec-feature-engineering}

There are points that distinguish the training and deployment for models. One of them is that, in the training process, we can see the whole batch. Whereas, only a partial time series are recorded in a production system for the application that the models are part of.

This leads to the reasons for our approaches when we carry out the feature engineering process. That is

> We conduct algorithms that receive a time window of time series as input. The outcomes are features detected by the algorithms.

This section is dedicated to introduce the algorithm and some insights behind them. The order of discussed feature detection is to follow the models' inputs in [@sec-baseline].

### Volumn of main mixer before discharging

The time period before the discharge happens is the phase where the products are stable and ready.