@article{CHANDRASHEKAR201416,
title = {A survey on feature selection methods},
journal = {Computers & Electrical Engineering},
volume = {40},
number = {1},
pages = {16-28},
year = {2014},
note = {40th-year commemorative issue},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2013.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S0045790613003066},
author = {Girish Chandrashekar and Ferat Sahin},
abstract = {Plenty of feature selection methods are available in literature due to the availability of data with hundreds of variables leading to data with very high dimension. Feature selection methods provides us a way of reducing computation time, improving prediction performance, and a better understanding of the data in machine learning or pattern recognition applications. In this paper we provide an overview of some of the methods present in literature. The objective is to provide a generic introduction to variable elimination which can be applied to a wide array of machine learning problems. We focus on Filter, Wrapper and Embedded methods. We also apply some of the feature selection techniques on standard datasets to demonstrate the applicability of feature selection techniques.}
}
@Manual{shiny,
  title = {shiny: Web Application Framework for R},
  author = {Winston Chang and Joe Cheng and JJ Allaire and Carson Sievert and Barret Schloerke and Yihui Xie and Jeff Allen and Jonathan McPherson and Alan Dipert and Barbara Borges},
  year = {2024},
  note = {R package version 1.8.0.9000, 
https://github.com/rstudio/shiny},
  url = {https://shiny.posit.co/},
}
@article{guyon2003introduction,
  title={An introduction to variable and feature selection},
  author={Guyon, Isabelle and Elisseeff, Andr{\'e}},
  journal={Journal of machine learning research},
  volume={3},
  number={Mar},
  pages={1157--1182},
  year={2003}
}
@article{xu2010discriminative,
  title={Discriminative semi-supervised feature selection via manifold regularization},
  author={Xu, Zenglin and King, Irwin and Lyu, Michael Rung-Tsong and Jin, Rong},
  journal={IEEE Transactions on Neural networks},
  volume={21},
  number={7},
  pages={1033--1047},
  year={2010},
  publisher={IEEE}
}
@article{KOHAVI1997273,
title = {Wrappers for feature subset selection},
journal = {Artificial Intelligence},
volume = {97},
number = {1},
pages = {273-324},
year = {1997},
note = {Relevance},
issn = {0004-3702},
doi = {https://doi.org/10.1016/S0004-3702(97)00043-X},
url = {https://www.sciencedirect.com/science/article/pii/S000437029700043X},
author = {Ron Kohavi and George H. John},
keywords = {Classification, Feature selection, Wrapper, Filter},
abstract = {In the feature subset selection problem, a learning algorithm is faced with the problem of selecting a relevant subset of features upon which to focus its attention, while ignoring the rest. To achieve the best possible performance with a particular learning algorithm on a particular training set, a feature subset selection method should consider how the algorithm and the training set interact. We explore the relation between optimal feature subset selection and relevance. Our wrapper method searches for an optimal feature subset tailored to a particular algorithm and a domain. We study the strengths and weaknesses of the wrapper approach and show a series of improved designs. We compare the wrapper approach to induction without feature subset selection and to Relief, a filter approach to feature subset selection. Significant improvement in accuracy is achieved for some datasets for the two families of induction algorithms used: decision trees and Naive-Bayes.}
}
@article{battiti1994using,
  title={Using mutual information for selecting features in supervised neural net learning},
  author={Battiti, Roberto},
  journal={IEEE Transactions on neural networks},
  volume={5},
  number={4},
  pages={537--550},
  year={1994},
  publisher={IEEE}
}
@ARTICLE{Kwak2002,
  author={Kwak, N. and Chong-Ho Choi},
  journal={IEEE Transactions on Neural Networks}, 
  title={Input feature selection for classification problems}, 
  year={2002},
  volume={13},
  number={1},
  pages={143-159},
  keywords={Mutual information;Neural networks;Biological neural networks;Principal component analysis;Decision trees;High performance computing;Information analysis;Data mining;Educational technology;Educational programs},
  doi={10.1109/72.977291}}
  @article{peng2005feature,
  title={Feature selection based on mutual information criteria of max-dependency, max-relevance, and min-redundancy},
  author={Peng, Hanchuan and Long, Fuhui and Ding, Chris},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={27},
  number={8},
  pages={1226--1238},
  year={2005},
  publisher={IEEE}
}
@article{guyon2002gene,
  title={Gene selection for cancer classification using support vector machines},
  author={Guyon, Isabelle and Weston, Jason and Barnhill, Stephen and Vapnik, Vladimir},
  journal={Machine learning},
  volume={46},
  pages={389--422},
  year={2002},
  publisher={Springer}
}
@article{haury2011influence,
  title={The influence of feature selection methods on accuracy, stability and interpretability of molecular signatures},
  author={Haury, Anne-Claire and Gestraud, Pierre and Vert, Jean-Philippe},
  journal={PloS one},
  volume={6},
  number={12},
  pages={e28210},
  year={2011},
  publisher={Public Library of Science San Francisco, USA}
}
@article{abeel2010robust,
  title={Robust biomarker identification for cancer diagnosis with ensemble feature selection methods},
  author={Abeel, Thomas and Helleputte, Thibault and Van de Peer, Yves and Dupont, Pierre and Saeys, Yvan},
  journal={Bioinformatics},
  volume={26},
  number={3},
  pages={392--398},
  year={2010},
  publisher={Oxford University Press}
}
@Article{app12031353,
AUTHOR = {Islam, Mir Riyanul and Ahmed, Mobyen Uddin and Barua, Shaibal and Begum, Shahina},
TITLE = {A Systematic Review of Explainable Artificial Intelligence in Terms of Different Application Domains and Tasks},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {1353},
URL = {https://www.mdpi.com/2076-3417/12/3/1353},
ISSN = {2076-3417},
ABSTRACT = {Artificial intelligence (AI) and machine learning (ML) have recently been radically improved and are now being employed in almost every application domain to develop automated or semi-automated systems. To facilitate greater human acceptability of these systems, explainable artificial intelligence (XAI) has experienced significant growth over the last couple of years with the development of highly accurate models but with a paucity of explainability and interpretability. The literature shows evidence from numerous studies on the philosophy and methodologies of XAI. Nonetheless, there is an evident scarcity of secondary studies in connection with the application domains and tasks, let alone review studies following prescribed guidelines, that can enable researchers’ understanding of the current trends in XAI, which could lead to future research for domain- and application-specific method development. Therefore, this paper presents a systematic literature review (SLR) on the recent developments of XAI methods and evaluation metrics concerning different application domains and tasks. This study considers 137 articles published in recent years and identified through the prominent bibliographic databases. This systematic synthesis of research articles resulted in several analytical findings: XAI methods are mostly developed for safety-critical domains worldwide, deep learning and ensemble models are being exploited more than other types of AI/ML models, visual explanations are more acceptable to end-users and robust evaluation metrics are being developed to assess the quality of explanations. Research studies have been performed on the addition of explanations to widely used AI/ML models for expert users. However, more attention is required to generate explanations for general users from sensitive domains such as finance and the judicial system.},
DOI = {10.3390/app12031353}
}
@Article{vilone2021,
AUTHOR = {Vilone, Giulia and Longo, Luca},
TITLE = {Classification of Explainable Artificial Intelligence Methods through Their Output Formats},
JOURNAL = {Machine Learning and Knowledge Extraction},
VOLUME = {3},
YEAR = {2021},
NUMBER = {3},
PAGES = {615--661},
URL = {https://www.mdpi.com/2504-4990/3/3/32},
ISSN = {2504-4990},
ABSTRACT = {Machine and deep learning have proven their utility to generate data-driven models with high accuracy and precision. However, their non-linear, complex structures are often difficult to interpret. Consequently, many scholars have developed a plethora of methods to explain their functioning and the logic of their inferences. This systematic review aimed to organise these methods into a hierarchical classification system that builds upon and extends existing taxonomies by adding a significant dimension—the output formats. The reviewed scientific papers were retrieved by conducting an initial search on Google Scholar with the keywords “explainable artificial intelligence”; “explainable machine learning”; and “interpretable machine learning”. A subsequent iterative search was carried out by checking the bibliography of these articles. The addition of the dimension of the explanation format makes the proposed classification system a practical tool for scholars, supporting them to select the most suitable type of explanation format for the problem at hand. Given the wide variety of challenges faced by researchers, the existing XAI methods provide several solutions to meet the requirements that differ considerably between the users, problems and application fields of artificial intelligence (AI). The task of identifying the most appropriate explanation can be daunting, thus the need for a classification system that helps with the selection of methods. This work concludes by critically identifying the limitations of the formats of explanations and by providing recommendations and possible future research directions on how to build a more generally applicable XAI method. Future work should be flexible enough to meet the many requirements posed by the widespread use of AI in several fields, and the new regulations.},
DOI = {10.3390/make3030032}
}
@article{gagolewski_stringi_2022,
	title = {\textbf{stringi} : {Fast} and {Portable} {Character} {String} {Processing} in \textit{{R}}},
	volume = {103},
	issn = {1548-7660},
	shorttitle = {\textbf{stringi}},
	url = {https://www.jstatsoft.org/v103/i02/},
	doi = {10.18637/jss.v103.i02},
	language = {en},
	number = {2},
	urldate = {2024-04-02},
	journal = {J. Stat. Soft.},
	author = {Gagolewski, Marek},
	year = {2022},
}
